{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6dc5ee1",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import pymorphy3\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import requests\n",
    "import folium\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b30e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# открытие файла с романом \"Идиот\"\n",
    "with open('book.txt', 'r', encoding='cp1251') as file: \n",
    "    book = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1533f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "book[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffcef6d",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('popular')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4ed610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# изменение списка стоп-слов\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "stop_words_adds = ['это','мочь',  'все', 'весь', 'свой', 'твой', 'мой', 'еще', 'знать', 'говорить', 'сказать', 'который', 'очень', 'стать', 'хотеть', 'видеть', 'смотреть', 'чрез', 'спросить', 'сейчас', 'тотчас', 'начать', 'хотя', 'именно', 'давеча', 'сделать', 'тут', 'вдруг', 'пройти', 'кроме', 'впоследствии', 'здесь', 'пять', 'аль', 'эвона', 'эк', 'фью', 'ай', 'самый', 'ваш', 'слишком', 'точно', 'несколько']\n",
    "stop_words.update(stop_words_adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"разделение слов на токены и проверка на вхождение в список стоп-слов и список пунктуаций\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    preprocessed_text = []\n",
    "    for token in tokens:\n",
    "        if len(token) > 1 and token:\n",
    "            if morph.parse(token)[0].normal_form.lower().replace('ё', 'е') not in stop_words and token.isalpha():\n",
    "                preprocessed_text.append(token)\n",
    "    return \" \".join(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ac312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение на предложения\n",
    "book = book.replace('\\n', '')\n",
    "sentences = re.split(r'[.!?]+', book) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f53ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sentences = [preprocess(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1585d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_marks = set(['!', ',', '(', ')', ':', '-', '?', '.', '..', '...', '-'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae38b1",
   "metadata": {},
   "source": [
    "Нормализация слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478aa73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemma(text):\n",
    "    \"\"\"лемматизация слов\"\"\"\n",
    "    text_parts = text.split()\n",
    "    lemma = []\n",
    "    for w in text_parts:\n",
    "        if w not in punctuation_marks:\n",
    "            lemma.append(morph.parse(w)[0].normal_form.replace('ё', 'е'))\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae75066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cоздание списка нормализованных токенов для анализа дисперсии и анализа частотности слов\n",
    "book_ = ' '.join(processed_sentences)\n",
    "words = ' '.join(get_lemma(book_)).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da402436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормализация предложений\n",
    "sentences_ = [get_lemma(sentence) for sentence in processed_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_to_list = [' '.join(lst) for lst in sentences_]\n",
    "\n",
    "df = pd.DataFrame(zip(sentences, sentence_to_list),  columns=['sentences', 'sentences_clear']).dropna() # датафрейм из предложений романа\n",
    "df.to_csv('sentences.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8258f2f",
   "metadata": {},
   "source": [
    "#### Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24712107",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_parts = r'\\bЧАСТЬ\\s+\\w+\\b'\n",
    "chapters = re.findall(pattern_parts, book)\n",
    "print(*chapters, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8b5472",
   "metadata": {},
   "source": [
    "Историческоий период сюжета романа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb17b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = re.findall(r'\\d+', book) # поиск чисел в тексте\n",
    "print(numbers)\n",
    "print()\n",
    "print(\"По всей видимости, в тексте не указывается год событий\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# найдем словосочетания со словом \"век\"\n",
    "pattern_period = r'\\w+\\s+\\bвек[а-я]\\b'\n",
    "\n",
    "period = re.findall(pattern_period, book)\n",
    "period = set(period)\n",
    "print(*period, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e8bc1",
   "metadata": {},
   "source": [
    "В романе упоминается \"девятнадцатый век\", \"золотой век\" и \"наш век\". Вероянее всего, действия в романе описываются в период жизни автора романа Ф.М. Достоевского (1821-1881), в девятнадцатом веке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f26043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # разделим весь текст на части\n",
    "parts = re.split(pattern_parts, book)\n",
    "print(len(parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146664be",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_1 = parts[1] # первое значение в списке пустое, поэтому не записываем значение с индексом 0\n",
    "part_2 = parts[2]\n",
    "part_3 = parts[3]\n",
    "part_4 = parts[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(part_1), len(part_2), len(part_3), len(part_4)]\n",
    "labels = [f'Часть {i}' for i in range(1, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0777eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(labels, lengths)\n",
    "plt.xlabel(' ')\n",
    "plt.ylabel('Длина')\n",
    "plt.title('Размер частей')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc512cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_words = []\n",
    "for word in words:\n",
    "\n",
    "    parse = morph.parse(word)[0]\n",
    "    if 'Patr' not in parse.tag :\n",
    "        \n",
    "        parsed_words.append(word)        \n",
    "counter = Counter(parsed_words)\n",
    "\n",
    "top_words = counter.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e610090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=1000, height=600, background_color='white').generate_from_frequencies(counter)\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Список 100 наиболее частых слов романа \"Идиот\"\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef55bb14",
   "metadata": {},
   "source": [
    "#### Geographical objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d7669",
   "metadata": {},
   "source": [
    "Упоминание города в тексте может свидетельствовать о местоположении, где происходят события романа, а также о путях передвижения персонажей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc7330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_entity(marks):\n",
    "    \"\"\"поиск именнованных сущностей\"\"\"\n",
    "    entity = []\n",
    "    \n",
    "    mid = len(book) // 2\n",
    "    book_part1 = book[:mid]\n",
    "    book_part2 = book[mid:]\n",
    "\n",
    "    for part in [book_part1, book_part2]:\n",
    "        doc = nlp(part.lower())\n",
    "        entity_found = [ent.text for ent in doc.ents if ent.label_ in marks]\n",
    "    entity.extend(entity_found)\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e55554",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_list = search_entity(\"LOC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112abfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_list = [morph.parse(l)[0].normal_form.title() for l in locations_list if \"Name\" not in morph.parse(l)[0].tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_count = pd.Series(locations_list).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44344f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_filtered = locations_count[(locations_count >= 2) &(locations_count.index.str.count(' ') == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94153ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = locations_filtered.index\n",
    "sizes = locations_filtered.values\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.pie(\n",
    "    sizes,\n",
    "    labels=labels,\n",
    "    autopct='%d%%',\n",
    "    rotatelabels=True,\n",
    "    startangle=90,\n",
    "    wedgeprops={'linewidth': 1, 'edgecolor': 'white'})\n",
    "\n",
    "plt.title('Локации  и места в романе \"Идиот\"\\n', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f2259",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = locations_filtered.reset_index()\n",
    "locations_df.columns = ['location', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed57847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(city_name):\n",
    "    \"\"\"получение координат\"\"\"\n",
    "    url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {\n",
    "        'q': city_name,\n",
    "        'format': 'json',\n",
    "        'limit': 1\n",
    "    }\n",
    "    headers = {'User-Agent': 'MyApp/1.0'}\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            lat = float(data[0]['lat'])\n",
    "            lon = float(data[0]['lon'])\n",
    "            return lat, lon\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coordinates(df):\n",
    "    \"\"\"добавление координатв дф\"\"\"\n",
    "    lats = []\n",
    "    lons = []\n",
    "\n",
    "    for index, row in locations_df.iterrows():\n",
    "        coords = get_coordinates(row['location'])\n",
    "        if coords:\n",
    "            lats.append(coords[0])\n",
    "            lons.append(coords[1])\n",
    "        else:\n",
    "            lats.append(None)\n",
    "            lons.append(None)\n",
    "\n",
    "    locations_df['latitude'] = lats\n",
    "    locations_df['longitude'] = lons\n",
    "\n",
    "    return locations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44137d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = add_coordinates(locations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1022344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_lat = locations_df['latitude'].mean()\n",
    "center_lon = locations_df['longitude'].mean()\n",
    "\n",
    "map = folium.Map(\n",
    "    location=[center_lat, center_lon],\n",
    "    zoom_start=4,\n",
    "    min_zoom=4,\n",
    "    max_zoom=4,\n",
    "    control_scale=False,        \n",
    "    zoom_control=False      \n",
    ")\n",
    "\n",
    "# Добавляем маркеры\n",
    "for _, row in locations_df.iterrows():\n",
    "    if pd.notnull(row['latitude']) and pd.notnull(row['longitude']):\n",
    "        folium.Marker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            popup=row['location']        \n",
    ").add_to(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14df6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba4906f",
   "metadata": {},
   "source": [
    "#### Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d084b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d033833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_characters():\n",
    "    \"\"\"поиск имен\"\"\"\n",
    "    names_list = search_entity(\"PER\")  # получение именованных сущностей\n",
    "    \n",
    "\n",
    "    def is_name_or_patronymic(word):\n",
    "        \"\"\"определение тегов имен\"\"\"\n",
    "        tags = morph.parse(word)[0].tag\n",
    "        return any(tag in tags for tag in ['Name', 'Surn', 'Patr'])\n",
    "\n",
    "    def is_valid_name(name):\n",
    "        \"\"\"проверка на валидность имен\"\"\"\n",
    "        return all(is_name_or_patronymic(w) for w in name.split())\n",
    "\n",
    "    names_filtered = [name for name in names_list if is_valid_name(name)]\n",
    "\n",
    "    def remove_short_words(name):\n",
    "        \"\"\"удаление коротких слов\"\"\"\n",
    "        return ' '.join(w for w in name.split() if len(w) > 2)\n",
    "\n",
    "    names_filtered = [remove_short_words(name) for name in names_filtered]\n",
    "\n",
    "    def not_only_patronymic(name):\n",
    "        \"\"\"удаление строк, состоящих только из отчества\"\"\"\n",
    "        parts = name.split()\n",
    "        tags_list = [morph.parse(part)[0].tag for part in parts]\n",
    "        has_patronymic = any('Patr' in tags for tags in tags_list)\n",
    "        return len(parts) > 1 or not has_patronymic\n",
    "\n",
    "    names_filtered1 = [name for name in names_filtered if not_only_patronymic(name)]\n",
    "\n",
    "    names = []\n",
    "    for name in names_filtered1:\n",
    "        if not isinstance(name, str):\n",
    "            names.append(name)\n",
    "            continue\n",
    "            \n",
    "        parts = name.split()\n",
    "        tags_list = [morph.parse(part)[0].tag for part in parts]\n",
    "\n",
    "        counts = {\n",
    "            'Name': sum('Name' in t for t in tags_list),\n",
    "            'Patr': sum('Patr' in t for t in tags_list),\n",
    "            'Surn': sum('Surn' in t for t in tags_list),\n",
    "        }\n",
    "\n",
    "        for key in ['Name', 'Patr', 'Surn']:\n",
    "            if counts[key] >= 2:\n",
    "                target_tag = key\n",
    "                break\n",
    "        else:\n",
    "            target_tag = None\n",
    "\n",
    "        if target_tag:\n",
    "            for part in parts:\n",
    "                if target_tag in morph.parse(part)[0].tag:\n",
    "                    names.append(part)\n",
    "                    break\n",
    "        else:\n",
    "            names.append(name)\n",
    "\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = get_characters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5282c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_names = sorted(names, key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b687c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединение различных вариантов имен в группы\n",
    "tags_cache = {}\n",
    "\n",
    "def get_tags(word):\n",
    "    if word not in tags_cache:\n",
    "        parse = morph.parse(word)[0]\n",
    "        tags_cache[word] = set(str(parse.tag).split())\n",
    "    return tags_cache[word]\n",
    "\n",
    "def are_similar(name1, name2, threshold=81):\n",
    "    \"\"\"проверка пересечения тегов слов\"\"\"\n",
    "    tags1 = get_tags(name1)\n",
    "    tags2 = get_tags(name2)\n",
    "    if not tags1.intersection(tags2):\n",
    "        return False\n",
    "     # проверка на сходство строк\n",
    "    ratio = (fuzz.partial_ratio(name1, name2) + fuzz.token_set_ratio(name1, name2) + fuzz.ratio(name1, name2)) / 3\n",
    "    return ratio >= threshold\n",
    "\n",
    "\n",
    "def normalize_name(name):\n",
    "    \"\"\"приведение слова к нормальной форме\"\"\"\n",
    "    parts_name = name.split()\n",
    "    normalized = []\n",
    "    for word in parts_name:\n",
    "        parse = morph.parse(word)[0]\n",
    "        normalized.append(parse.normal_form)\n",
    "    return ' '.join(normalized)\n",
    "\n",
    "groups = []\n",
    "for name in sorted_names:\n",
    "    name_base = normalize_name(name)\n",
    "    placed = False\n",
    "    for group in groups:\n",
    "        base_group_name = normalize_name(group[0])\n",
    "        if are_similar(base_group_name, name_base):\n",
    "            group.append(name)\n",
    "            placed = True\n",
    "            break\n",
    "    if not placed:\n",
    "        groups.append([name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec6018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c723da",
   "metadata": {},
   "source": [
    "Поиск главных персонажей романа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = {}\n",
    "\n",
    "for group in groups:\n",
    "    for name in group:\n",
    "        name = str(name).title()\n",
    "        parts_name = name.split()\n",
    "\n",
    "        if len(parts_name) > 1:\n",
    "            first_word, second_word = parts_name[0], parts_name[1]\n",
    "            tags = morph.parse(second_word)[0].tag\n",
    "            if 'nomn' in tags and not first_word.endswith(('ом', 'у', 'ы')):\n",
    "                persons[name] = len(group)\n",
    "                break\n",
    "        else:\n",
    "            tags = morph.parse(name)[0].tag\n",
    "            if 'nomn' in tags:\n",
    "                persons[name] = len(group)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_persons = dict(sorted(persons.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_15_persons = dict(list(main_persons.items())[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5cdad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(top_15_persons.keys())\n",
    "values = list(top_15_persons.values())\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(keys, values)\n",
    "plt.title('ТОП-15 наиболее упоминаемых героев романа')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "top15_groups = sorted(groups, key=len, reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1cb360",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_variations = []\n",
    "for group in top15_groups:\n",
    "    first_words = [name.split()[0] for name in group]\n",
    "    name_variations.append(first_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a512d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_variations = [list(set(name)) for name in name_variations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40986bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dispersion(text, name_list, flag=None):\n",
    "    \"\"\"поиск слова в тексте\"\"\"\n",
    "    if flag:\n",
    "        return [flag if any(wi in w for wi in name_list) else np.nan for w in text]\n",
    "    else:\n",
    "        return [i+1 if word in w else np.nan for i, w in enumerate(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df07d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_results = []\n",
    "\n",
    "for name_var in name_variations:\n",
    "    result = get_dispersion(words, name_var, flag=1)\n",
    "    dispersion_results.append(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe961cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "\n",
    "max_length = max(len(res) for res in dispersion_results)\n",
    "\n",
    "\n",
    "# графики частотности упоминания персон\n",
    "for i, res in enumerate(dispersion_results):\n",
    "    offset = i\n",
    "    y_vals = np.array([np.nan if np.isnan(x) else x + offset for x in res])\n",
    "    ax.scatter(np.arange(len(y_vals)), y_vals, s=20, alpha=0.3, zorder=2)\n",
    "\n",
    "\n",
    "xticks_positions = np.linspace(1, 4, 5).astype(int).tolist()\n",
    "ax.set_xticklabels([f'{x:.0f}%' for x in np.linspace(0, 100, 6)], fontsize=16)\n",
    "ax.set_xticks(np.linspace(0, max_length, 6).astype(int))\n",
    "\n",
    "ax.set_yticks(range(0, len(keys)+1))\n",
    "ax.set_yticklabels([''] + [f\"{n.title()} ({v})\" for n, v in zip(keys, values)], fontsize=16)\n",
    "\n",
    "\n",
    "ax.set_xlim([0, max_length])\n",
    "ax.set_title('Частота упоминаний персонажей в течение всего романа (%)\\n', fontsize=20)\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a739c03a",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d481c9",
   "metadata": {},
   "source": [
    "#### Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea851c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deeppavlov import build_model, configs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c775bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sentences.csv', encoding ='utf-8')\n",
    "df = df.dropna()\n",
    "df['sentences_clear'] = df['sentences_clear'].dropna().fillna('') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d338e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(configs.classifiers.rusentiment_bert, download=False)\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"определение тональности предложения\"\"\"\n",
    "    result = model([text])\n",
    "    if isinstance(result, list):\n",
    "        sentiment = result[0]\n",
    "    else:\n",
    "        sentiment = result\n",
    "    if sentiment == 'positive':\n",
    "        return 1\n",
    "    elif sentiment == 'negative':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d6357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentences_clear'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35261513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rolling_mean'] = df['sentiment'].rolling(window=3).mean()\n",
    "df['rolling_mean'] = df['rolling_mean'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf1302",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 3))\n",
    "plt.plot(df.index, df['sentiment'])\n",
    "plt.ylabel('Sentiment')\n",
    "plt.title('Изменение тональности текста', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7eecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 3))\n",
    "df['sentiment_smooth'] = df['sentiment'].rolling(window=10).mean()\n",
    "plt.plot(df.index, df['sentiment_smooth'])\n",
    "plt.ylabel('Sentiment (скользящее среднее)')\n",
    "plt.title('Изменение тональности текста (сглаженное)', fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ = df['sentiment_smooth'].max()\n",
    "min_ = df['sentiment_smooth'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65433f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if row['sentiment_smooth'] == max_:\n",
    "        print( row['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d07747",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if row['sentiment_smooth'] == min_:\n",
    "        print(row['sentences'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
